{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d20717-9e78-4165-a23b-12172f439137",
   "metadata": {},
   "source": [
    "<h1>Automated Response Generation for Customer Support</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34381a68-4f08-4b04-b5bb-6be6066c76c4",
   "metadata": {},
   "source": [
    "**Step-by-Step Guide**\n",
    "1. Import Required Libraries\n",
    "2. Load and Preprocess Data\n",
    "3. Tokenize the Data\n",
    "4. Create the Seq2Seq Model\n",
    "5. Train the Model\n",
    "6. Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4376a9-d64c-4777-8bd4-86da7069ac7a",
   "metadata": {},
   "source": [
    "<h3>Import Required Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83f2256-1a88-46c2-9fa5-ec199018bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9022b4-ec04-4d51-b08a-0ed2e72fade2",
   "metadata": {},
   "source": [
    "<h3>Load and Preprocess Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a187370-a095-41ce-a378-2730e9cf8a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My order hasn't arrived yet.</td>\n",
       "      <td>We apologize for the inconvenience. Can you pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I received a damaged product.</td>\n",
       "      <td>We apologize for the inconvenience. Can you pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need to return an item.</td>\n",
       "      <td>Certainly. Please provide your order number an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to change my shipping address.</td>\n",
       "      <td>No problem. Can you please provide your order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have a question about my bill.</td>\n",
       "      <td>We'd be happy to help. Can you please provide ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   query  \\\n",
       "0           My order hasn't arrived yet.   \n",
       "1          I received a damaged product.   \n",
       "2              I need to return an item.   \n",
       "3  I want to change my shipping address.   \n",
       "4       I have a question about my bill.   \n",
       "\n",
       "                                            response  \n",
       "0  We apologize for the inconvenience. Can you pl...  \n",
       "1  We apologize for the inconvenience. Can you pl...  \n",
       "2  Certainly. Please provide your order number an...  \n",
       "3  No problem. Can you please provide your order ...  \n",
       "4  We'd be happy to help. Can you please provide ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\shiva\\Downloads\\Customer-Support.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f0b908-f636-4e13-bae1-47ee9c386df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query       74\n",
       "response    74\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87f3db0-77f7-489b-ba98-56c4f31fabd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74 entries, 0 to 73\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   query     74 non-null     object\n",
      " 1   response  74 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc4ba504-ca40-4c37-97e8-0a13d98624fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract queries and responses\n",
    "queries = data['query'].values\n",
    "responses = data['response'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2dbdbd2-f0ba-42f2-9417-f802ef2b4e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My order hasn't arrived yet.\n",
      "I received a damaged product.\n",
      "I need to return an item.\n",
      "I want to change my shipping address.\n",
      "I have a question about my bill.\n"
     ]
    }
   ],
   "source": [
    "# first 5 records of queries\n",
    "for i in range(0,5):\n",
    "    print(queries[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03b9f5f5-6e37-411e-bbe5-623b568a70ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We apologize for the inconvenience. Can you please provide your order number so we can investigate?\n",
      "We apologize for the inconvenience. Can you please provide a photo of the damaged product so we can assist you further?\n",
      "Certainly. Please provide your order number and reason for return, and we will provide you with instructions on how to proceed.\n",
      "No problem. Can you please provide your order number and the new shipping address you'd like to use?\n",
      "We'd be happy to help. Can you please provide your account number and a brief description of your question?\n"
     ]
    }
   ],
   "source": [
    "# first 5 records of responses\n",
    "for i in range(0,5):\n",
    "    print(responses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54be6571-c5b8-4f87-9680-d3f43ae1f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end tokens to responses\n",
    "responses = ['<start> ' + response + ' <end>' for response in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6078df22-3ed1-4610-baf4-53a161e57f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> We apologize for the inconvenience. Can you please provide your order number so we can investigate? <end>\n",
      "<start> We apologize for the inconvenience. Can you please provide a photo of the damaged product so we can assist you further? <end>\n",
      "<start> Certainly. Please provide your order number and reason for return, and we will provide you with instructions on how to proceed. <end>\n",
      "<start> No problem. Can you please provide your order number and the new shipping address you'd like to use? <end>\n",
      "<start> We'd be happy to help. Can you please provide your account number and a brief description of your question? <end>\n"
     ]
    }
   ],
   "source": [
    "# first 5 records of responses with start and end tokens\n",
    "for i in range(0,5):\n",
    "    print(responses[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4908dc-3f94-4977-a6c7-519f9a60802d",
   "metadata": {},
   "source": [
    "<h3>Tokenize the Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8e2a343-bc5b-4b2a-82cc-2a82fb8a654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizers\n",
    "query_tokenizer = Tokenizer(filters='')\n",
    "response_tokenizer = Tokenizer(filters='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4bb480d-a4e9-4416-a382-159eca124ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit tokenizers on the data\n",
    "query_tokenizer.fit_on_texts(queries)\n",
    "response_tokenizer.fit_on_texts(responses)\n",
    "\n",
    "# Ensure '<start>' and '<end>' tokens are in the vocabulary\n",
    "if '<start>' not in response_tokenizer.word_index:\n",
    "    response_tokenizer.word_index['<start>'] = len(response_tokenizer.word_index) + 1\n",
    "if '<end>' not in response_tokenizer.word_index:\n",
    "    response_tokenizer.word_index['<end>'] = len(response_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "916ddc89-c0b9-4972-9fb2-76e2fa51a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to sequences\n",
    "query_sequences = query_tokenizer.texts_to_sequences(queries)\n",
    "response_sequences = response_tokenizer.texts_to_sequences(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "180fa5d7-fb3f-47ef-bd05-5949fea61573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "max_query_len = max(len(seq) for seq in query_sequences)\n",
    "max_response_len = max(len(seq) for seq in response_sequences)\n",
    "\n",
    "query_padded = pad_sequences(query_sequences, maxlen=max_query_len, padding='post')\n",
    "response_padded = pad_sequences(response_sequences, maxlen=max_response_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94cc268a-18d1-4303-b609-d178528dc7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and target sequences for the decoder\n",
    "decoder_input_data = response_padded[:, :-1]\n",
    "decoder_target_data = response_padded[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e7ccf-b4f2-48f0-8e07-605a899065d4",
   "metadata": {},
   "source": [
    "<h3>Create the Seq2Seq Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b38525d8-d675-4097-91c2-c1d6f64d842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "vocab_size_query = len(query_tokenizer.word_index) + 1\n",
    "vocab_size_response = len(response_tokenizer.word_index) + 1\n",
    "embedding_dim = 256\n",
    "units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36351dee-1c69-46c4-8792-22321e78cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(max_query_len,))\n",
    "encoder_embedding = tf.keras.layers.Embedding(vocab_size_query, embedding_dim)(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = tf.keras.layers.LSTM(units, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ba9cfa9-5bf9-427a-9593-155cfc1060f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(max_response_len - 1,))\n",
    "decoder_embedding = tf.keras.layers.Embedding(vocab_size_response, embedding_dim)(decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = tf.keras.layers.Dense(vocab_size_response, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba3b4b2a-816f-4251-a107-7dda81b0246c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 11)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 33)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 11, 256)      52992       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 33, 256)      83200       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 512),        1574912     ['embedding[0][0]']              \n",
      "                                 (None, 512),                                                     \n",
      "                                 (None, 512)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 33, 512),    1574912     ['embedding_1[0][0]',            \n",
      "                                 (None, 512),                     'lstm[0][1]',                   \n",
      "                                 (None, 512)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 33, 325)      166725      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,452,741\n",
      "Trainable params: 3,452,741\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b810dc80-4e29-43e5-b13c-5c43ee6f19cb",
   "metadata": {},
   "source": [
    "<h3>Train the Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e693de0b-abfa-4bae-afe2-8aba7e80a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 5.7836 - val_loss: 5.7475\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 5.7307 - val_loss: 5.6994\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 5.6600 - val_loss: 5.5930\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 5.5059 - val_loss: 5.0745\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 4.8087 - val_loss: 4.9606\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 4.4941 - val_loss: 4.7845\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 4.3374 - val_loss: 4.4626\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 4.0988 - val_loss: 4.4899\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 4.1810 - val_loss: 4.4405\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 4.1377 - val_loss: 4.3080\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 3.9859 - val_loss: 4.2363\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 3.8893 - val_loss: 4.2376\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 3.8739 - val_loss: 4.2182\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 3.8531 - val_loss: 4.1501\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 3.7968 - val_loss: 4.0832\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 3.7474 - val_loss: 4.0458\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 3.7234 - val_loss: 4.0176\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 3.6966 - val_loss: 3.9783\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 3.6452 - val_loss: 3.9310\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 3.5765 - val_loss: 3.8915\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 3.5133 - val_loss: 3.8608\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 3.4626 - val_loss: 3.8092\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 3.4010 - val_loss: 3.7280\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 3.3341 - val_loss: 3.6863\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 3.3201 - val_loss: 3.6368\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 3.2380 - val_loss: 3.6668\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 3.2069 - val_loss: 3.6326\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 3.1671 - val_loss: 3.5542\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 3.1605 - val_loss: 3.5349\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 3.1140 - val_loss: 3.5801\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 3.0891 - val_loss: 3.5647\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 3.0635 - val_loss: 3.4903\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 3.0319 - val_loss: 3.4662\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 3.0120 - val_loss: 3.4922\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 2.9773 - val_loss: 3.4977\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 2.9557 - val_loss: 3.4251\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 2.9227 - val_loss: 3.3967\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 2.9072 - val_loss: 3.4594\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 2.8840 - val_loss: 3.4333\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 2.8585 - val_loss: 3.3547\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 2.8457 - val_loss: 3.3944\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 2.8117 - val_loss: 3.4021\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 2.7954 - val_loss: 3.3258\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 2.7769 - val_loss: 3.3580\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 2.7473 - val_loss: 3.3656\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 2.7272 - val_loss: 3.2987\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 2.7205 - val_loss: 3.5009\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 2.7431 - val_loss: 3.2875\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 2.6916 - val_loss: 3.3451\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 2.6483 - val_loss: 3.4030\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 2.6419 - val_loss: 3.3013\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 2.6171 - val_loss: 3.3306\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 2.5889 - val_loss: 3.3947\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 2.5787 - val_loss: 3.2808\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 2.5563 - val_loss: 3.3488\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 2.5312 - val_loss: 3.3027\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 2.5086 - val_loss: 3.2777\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 2.4903 - val_loss: 3.3890\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 2.4848 - val_loss: 3.2258\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 2.5194 - val_loss: 3.7368\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 2.6458 - val_loss: 3.3960\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 2.4497 - val_loss: 3.2981\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 2.5814 - val_loss: 3.3119\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 2.4179 - val_loss: 3.5427\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 2.4594 - val_loss: 3.5127\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 2.4332 - val_loss: 3.2841\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 2.3730 - val_loss: 3.2038\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 2.3964 - val_loss: 3.2415\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 2.3200 - val_loss: 3.3471\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 2.3343 - val_loss: 3.3451\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 2.3218 - val_loss: 3.2333\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 2.2718 - val_loss: 3.1546\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 2.2716 - val_loss: 3.1746\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 2.2405 - val_loss: 3.2643\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 2.2173 - val_loss: 3.2996\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 2.2090 - val_loss: 3.2175\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 2.1701 - val_loss: 3.1229\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 2.1582 - val_loss: 3.1097\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 2.1426 - val_loss: 3.1680\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 2.1095 - val_loss: 3.2245\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 2.0966 - val_loss: 3.1938\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 2.0692 - val_loss: 3.1205\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 2.0490 - val_loss: 3.0906\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 2.0298 - val_loss: 3.1265\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 1.9996 - val_loss: 3.1625\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 1.9856 - val_loss: 3.1170\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 1.9559 - val_loss: 3.0631\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 1.9344 - val_loss: 3.0783\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 1.9105 - val_loss: 3.1275\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 1.8882 - val_loss: 3.1119\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 1.8605 - val_loss: 3.0528\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.8387 - val_loss: 3.0576\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 1.8112 - val_loss: 3.1053\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 1.7887 - val_loss: 3.0628\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 1.7604 - val_loss: 3.0105\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 1s 500ms/step - loss: 1.7376 - val_loss: 3.0598\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 1.7090 - val_loss: 3.0576\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 1.6831 - val_loss: 2.9922\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 1.6587 - val_loss: 3.0338\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 1.6282 - val_loss: 3.0380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef91ec79d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "model.fit([query_padded, decoder_input_data], \n",
    "          decoder_target_data, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "457c6e43-5aeb-492f-b0c7-41acbd2996e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder model\n",
    "encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "badb508e-8651-483b-89e4-1e75c1d96c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the decoder model\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(units,))\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = tf.keras.models.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8c05ebc-e5ca-48ec-8666-118be06b107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode function\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = response_tokenizer.word_index['<start>']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = response_tokenizer.index_word[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_word\n",
    "\n",
    "        # Exit condition: either hit max length or find stop token.\n",
    "        if (sampled_word == '<end>' or\n",
    "           len(decoded_sentence) > 2 * max_response_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5eadb9-b361-4ca6-85d0-2b505aaa3fb2",
   "metadata": {},
   "source": [
    "<h3>Test the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6afa855d-87fa-41c1-8af5-6b7f376386e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 33) for input KerasTensor(type_spec=TensorSpec(shape=(None, 33), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "1/1 [==============================] - 1s 951ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "-\n",
      "Query: My order hasn't arrived yet.\n",
      "Response:  we apologize for the inconvenience. can you please provide your account email\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "-\n",
      "Query: I received a damaged product.\n",
      "Response:  we apologize for the inconvenience. can you please provide your account email\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "-\n",
      "Query: I need to return an item.\n",
      "Response:  certainly. can you please provide the product and and the and the you're you'd\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "-\n",
      "Query: I want to change my shipping address.\n",
      "Response:  certainly. can you please provide your order number and the and the the you'd\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "-\n",
      "Query: I have a question about my bill.\n",
      "Response:  we apologize for the inconvenience. can you please provide your account email\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "-\n",
      "Query: How do I cancel my subscription?\n",
      "Response:  we apologize for the can you please provide your account email so we can can\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "-\n",
      "Query: Can I get a refund for my purchase?\n",
      "Response:  certainly. can you please provide your your order number and the the the you'd\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "-\n",
      "Query: I'd like to track my order.\n",
      "Response:  certainly. can you please provide your order number and the the the the you'd\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "-\n",
      "Query: My account has been locked.\n",
      "Response:  we apologize for the inconvenience. can you please provide your account email\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "-\n",
      "Query: I can't find the item I'm looking for.\n",
      "Response:  we apologize for the can you please provide your account email so we can can\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(10):\n",
    "    input_seq = query_padded[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Query:', queries[seq_index])\n",
    "    print('Response:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fb91ef-f3b3-46b5-9a44-d177c7506bd4",
   "metadata": {},
   "source": [
    "**END**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
